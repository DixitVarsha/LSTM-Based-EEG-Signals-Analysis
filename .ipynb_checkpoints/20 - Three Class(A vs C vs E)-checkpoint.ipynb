{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a0380d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from time import sleep\n",
    "import os\n",
    "import warnings\n",
    "import pywt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import sklearn\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Bidirectional\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from scipy.stats import skew, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3148317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirA=\"./Datasets/setA/\"\n",
    "tempA=[]\n",
    "for file in os.listdir(dirA):\n",
    "    fl = dirA + file\n",
    "    tempA.append(fl)\n",
    "tempA = sorted(tempA)\n",
    "\n",
    "dirB=\"./Datasets/setB/\"\n",
    "tempB=[]\n",
    "for file in os.listdir(dirB):\n",
    "    fl = dirB + file\n",
    "    tempB.append(fl)\n",
    "tempB = sorted(tempB)\n",
    "\n",
    "dirC=\"./Datasets/setC/\"\n",
    "tempC=[]\n",
    "for file in os.listdir(dirC):\n",
    "    fl = dirC + file\n",
    "    tempC.append(fl)\n",
    "tempC = sorted(tempC)\n",
    "\n",
    "dirD=\"./Datasets/setD/\"\n",
    "tempD=[]\n",
    "for file in os.listdir(dirD):\n",
    "    fl = dirD + file\n",
    "    tempD.append(fl)\n",
    "tempD = sorted(tempD)\n",
    "\n",
    "dirE=\"./Datasets/setE/\"\n",
    "tempE=[]\n",
    "for file in os.listdir(dirE):\n",
    "    fl = dirE + file\n",
    "    tempE.append(fl)\n",
    "tempE = sorted(tempE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6c520d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ta=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempA)):\n",
    "    x = pd.read_table(tempA[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    ta.append(x)\n",
    "\n",
    "tb=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempB)):\n",
    "    x = pd.read_table(tempB[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    tb.append(x)\n",
    "\n",
    "tc=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempC)):\n",
    "    x = pd.read_table(tempC[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    tc.append(x)\n",
    "    \n",
    "td=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempD)):\n",
    "    x = pd.read_table(tempD[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    td.append(x)\n",
    "    \n",
    "te=[]\n",
    "st = 'A'\n",
    "for i in range(len(tempE)):\n",
    "    x = pd.read_table(tempE[i],header=None)\n",
    "    x.columns=[st+str(i)]\n",
    "    te.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc32b100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(table):\n",
    "    big_table=None\n",
    "    for tf in table:\n",
    "        big_table=pd.concat([big_table,tf],axis=1)\n",
    "    return big_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8053dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigA=table(ta)\n",
    "bigB=table(tb)\n",
    "bigC=table(tc)\n",
    "bigD=table(td)\n",
    "bigE=table(te)\n",
    "\n",
    "head=list(bigA.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "111b3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_mat(mat):\n",
    "    matx = np.zeros((len(mat),(len(head))))\n",
    "    for i in range(len(head)):\n",
    "        matx[:,i] = mat[head[i]]\n",
    "        sleep(0.01)\n",
    "    return matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885eeffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "matA = creat_mat(bigA)\n",
    "matB = creat_mat(bigB)\n",
    "matC = creat_mat(bigC)\n",
    "matD = creat_mat(bigD)\n",
    "matE = creat_mat(bigE) \n",
    "\n",
    "matA = np.nan_to_num(matA)\n",
    "matB = np.nan_to_num(matB)\n",
    "matC = np.nan_to_num(matC)\n",
    "matD = np.nan_to_num(matD)\n",
    "matE = np.nan_to_num(matE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c54a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples=np.arange(0,4097,1)\n",
    "plt.figure(figsize=(16,8),dpi=600)\n",
    "plt.subplot(3,1,1)\n",
    "plt.title('Normal')\n",
    "plt.plot(samples,matA[:,0],label='Normal',color='green')\n",
    "plt.subplot(3,1,2)\n",
    "plt.title('Inter-ictal')\n",
    "plt.plot(samples,matC[:,0],label='Inter-ictal',color='blue')\n",
    "plt.subplot(3,1,3)\n",
    "plt.title('Seizure')\n",
    "plt.plot(samples,matE[:,0],label='Seizure',color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956aee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "matN_out = np.zeros((1,100))\n",
    "X_data_N = np.concatenate((matA,matN_out), axis = 0) \n",
    "print(X_data_N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "matI_out = np.ones((1,100))\n",
    "X_data_I = np.concatenate((matC,matI_out), axis = 0) \n",
    "print(X_data_I.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0415145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matS_out = np.full((1,100),[2])\n",
    "X_data_S = np.concatenate((matE,matS_out), axis = 0) \n",
    "print(X_data_S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2ac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((X_data_N,X_data_I,X_data_S), axis =1)\n",
    "data = data.T\n",
    "c = 'A'\n",
    "col = []\n",
    "sig = []\n",
    "for i in range(np.size(data,1)-1):\n",
    "    col.append(st+str(i))\n",
    "for i in range(np.size(data,0)):\n",
    "    sig.append('S'+str(i))\n",
    "col.append('out')\n",
    "TotalData = pd.DataFrame(data, columns=col, index= sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = TotalData.drop(['out'], axis =1)\n",
    "target = TotalData['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa339e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = pywt.wavelist('bior')\n",
    "print(filters)\n",
    "print(len(filters))\n",
    "level =5\n",
    "w_name = 'bior6.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4fae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pywt.Wavelet(w_name)\n",
    "temp_cA = []\n",
    "temp_cD5 = []\n",
    "temp_cD4 = []\n",
    "temp_cD3 = []\n",
    "temp_cD2 = []\n",
    "temp_cD1 = []\n",
    "for i in matA.T:\n",
    "  cA,cD5,cD4,cD3,cD2,cD1 = pywt.wavedec(i, w, mode='constant', level=level)\n",
    "  temp_cA.append(cA)\n",
    "  temp_cD1.append(cD1)\n",
    "  temp_cD2.append(cD2)\n",
    "  temp_cD3.append(cD3)\n",
    "  temp_cD4.append(cD4)\n",
    "  temp_cD5.append(cD5)\n",
    "coeff_cA = np.array(temp_cA)\n",
    "coeff_cD1 = np.array(temp_cD1)\n",
    "coeff_cD2 = np.array(temp_cD2)\n",
    "coeff_cD3 = np.array(temp_cD3)\n",
    "coeff_cD4 = np.array(temp_cD4)\n",
    "coeff_cD5 = np.array(temp_cD5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a0626",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pywt.Wavelet(w_name)\n",
    "temp_cA_I = []\n",
    "temp_cD5_I = []\n",
    "temp_cD4_I = []\n",
    "temp_cD3_I = []\n",
    "temp_cD2_I = []\n",
    "temp_cD1_I = []\n",
    "for i in matC.T:\n",
    "  cA_I,cD5_I,cD4_I,cD3_I,cD2_I,cD1_I = pywt.wavedec(i, w, mode='constant', level=level)\n",
    "  temp_cA_I.append(cA_I)\n",
    "  temp_cD3_I.append(cD3_I)\n",
    "  temp_cD4_I.append(cD4_I)\n",
    "  temp_cD5_I.append(cD5_I)\n",
    "  temp_cD2_I.append(cD2_I)\n",
    "  temp_cD1_I.append(cD1_I)\n",
    "coeff_cA_I  = np.array(temp_cA_I)\n",
    "coeff_cD5_I = np.array(temp_cD5_I)\n",
    "coeff_cD4_I = np.array(temp_cD4_I)\n",
    "coeff_cD3_I = np.array(temp_cD3_I)\n",
    "coeff_cD2_I = np.array(temp_cD2_I)\n",
    "coeff_cD1_I = np.array(temp_cD1_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f187718",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = pywt.Wavelet(w_name)\n",
    "temp_cA_S = []\n",
    "temp_cD5_S = []\n",
    "temp_cD4_S = []\n",
    "temp_cD3_S = []\n",
    "temp_cD2_S = []\n",
    "temp_cD1_S = []\n",
    "for i in matE.T:\n",
    "  cA_S,cD5_S,cD4_S,cD3_S,cD2_S,cD1_S = pywt.wavedec(i, w, mode='constant', level=level)\n",
    "  temp_cA_S.append(cA_S)\n",
    "  temp_cD3_S.append(cD3_S)\n",
    "  temp_cD4_S.append(cD4_S)\n",
    "  temp_cD5_S.append(cD5_S)\n",
    "  temp_cD2_S.append(cD2_S)\n",
    "  temp_cD1_S.append(cD1_S)\n",
    "coeff_cA_S = np.array(temp_cA_S)\n",
    "coeff_cD5_S = np.array(temp_cD5_S)\n",
    "coeff_cD4_S = np.array(temp_cD4_S)\n",
    "coeff_cD3_S = np.array(temp_cD3_S)\n",
    "coeff_cD2_S = np.array(temp_cD2_S)\n",
    "coeff_cD1_S = np.array(temp_cD1_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seizure\n",
    "print(coeff_cA_S.shape)\n",
    "print(coeff_cD5_S.shape)\n",
    "print(coeff_cD4_S.shape)\n",
    "print(coeff_cD3_S.shape)\n",
    "print(coeff_cD2_S.shape)\n",
    "print(coeff_cD1_S.shape)\n",
    "\n",
    "#Interictal\n",
    "print(coeff_cA_I.shape)\n",
    "print(coeff_cD5_I.shape)\n",
    "print(coeff_cD4_I.shape)\n",
    "print(coeff_cD3_I.shape)\n",
    "print(coeff_cD2_I.shape)\n",
    "print(coeff_cD1_I.shape)\n",
    "\n",
    "#Normal\n",
    "print(coeff_cA.shape)\n",
    "print(coeff_cD5.shape)\n",
    "print(coeff_cD4.shape)\n",
    "print(coeff_cD3.shape)\n",
    "print(coeff_cD2.shape)\n",
    "print(coeff_cD1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc7216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_cA_total = np.concatenate([coeff_cA, coeff_cA_I,coeff_cA_S])\n",
    "coeff_cD1_total = np.concatenate([coeff_cD1, coeff_cD1_I,coeff_cD1_S])\n",
    "coeff_cD2_total = np.concatenate([coeff_cD2, coeff_cD2_I,coeff_cD2_S])\n",
    "coeff_cD3_total = np.concatenate([coeff_cD3, coeff_cD3_I,coeff_cD3_S])\n",
    "coeff_cD4_total = np.concatenate([coeff_cD4, coeff_cD4_I,coeff_cD4_S])\n",
    "coeff_cD5_total = np.concatenate([coeff_cD5, coeff_cD5_I,coeff_cD5_S])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe253b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(level+1,1,1)\n",
    "plt.ylabel('cA')\n",
    "plt.xlabel('Samples')\n",
    "plt.plot(np.arange(0,len(coeff_cA_total[0]),1),coeff_cA_total[0,:].T)\n",
    "\n",
    "plt.subplot(level+1,1,2)\n",
    "plt.ylabel('cD1')\n",
    "plt.xlabel('Samples')\n",
    "plt.plot(np.arange(0,len(coeff_cD1_total[0]),1),coeff_cD1_total[0,:].T)\n",
    "\n",
    "plt.subplot(level+1,1,3)\n",
    "plt.ylabel('cD2')\n",
    "plt.xlabel('Samples')\n",
    "plt.plot(np.arange(0,len(coeff_cD2_total[0]),1),coeff_cD2_total[0,:].T)\n",
    "\n",
    "plt.subplot(level+1,1,4)\n",
    "plt.ylabel('cD3')\n",
    "plt.xlabel('Samples')\n",
    "plt.plot(np.arange(0,len(coeff_cD3_total[0]),1),coeff_cD3_total[0,:].T)\n",
    "\n",
    "plt.subplot(level+1,1,5)\n",
    "plt.ylabel('cD4')\n",
    "plt.xlabel('Samples')\n",
    "plt.plot(np.arange(0,len(coeff_cD4_total[0]),1),coeff_cD4_total[0,:].T)\n",
    "\n",
    "plt.subplot(level+1,1,6)\n",
    "plt.ylabel('cD5')\n",
    "plt.xlabel('Samples')\n",
    "plt.plot(np.arange(0,len(coeff_cD5_total[0]),1),coeff_cD5_total[0,:].T)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34b179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_size = 4\n",
    "columns_name = list()\n",
    "for i in range(feature_size):\n",
    "    columns_name = columns_name + ['f'+str(i+1)]\n",
    "columns_name = columns_name + ['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9967fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_features(mat):\n",
    "    lis = list()\n",
    "    lis = lis + [kurtosis(mat)]\n",
    "    lis = lis + [np.var(mat)]\n",
    "    lis = lis + [skew(mat)]\n",
    "    lis = lis + [np.std(mat)]\n",
    "    sleep(0.01)\n",
    "             \n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class I and cA\n",
    "f1_cA_N    = np.zeros((100,1))\n",
    "f2_cA_N    = np.zeros((100,1))\n",
    "f3_cA_N    = np.zeros((100,1))\n",
    "f4_cA_N    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cA_N[i,0],f2_cA_N[i,0],f3_cA_N[i,0],f4_cA_N[i,0]]=build_features(coeff_cA.T[:,i])\n",
    "\n",
    "# # create features of class I and cD1\n",
    "# f1_cD1_N    = np.zeros((100,1))\n",
    "# f2_cD1_N    = np.zeros((100,1))\n",
    "# f3_cD1_N    = np.zeros((100,1))\n",
    "# f4_cD1_N    = np.zeros((100,1))\n",
    "\n",
    "# for i in range(100):\n",
    "#     [f1_cD1_N[i,0],f2_cD1_N[i,0],f3_cD1_N[i,0],f4_cD1_N[i,0]]=build_features(coeff_cD1.T[:,i])\n",
    "  \n",
    "# create features of class I and cD1\n",
    "f1_cD2_N   = np.zeros((100,1))\n",
    "f2_cD2_N   = np.zeros((100,1))\n",
    "f3_cD2_N   = np.zeros((100,1))\n",
    "f4_cD2_N   = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD2_N[i,0],f2_cD2_N[i,0],f3_cD2_N[i,0],f4_cD2_N[i,0]]=build_features(coeff_cD2.T[:,i])\n",
    "\n",
    "# create features of class I and cD3\n",
    "f1_cD3_N   = np.zeros((100,1))\n",
    "f2_cD3_N   = np.zeros((100,1))\n",
    "f3_cD3_N   = np.zeros((100,1))\n",
    "f4_cD3_N   = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD3_N[i,0],f2_cD3_N[i,0],f3_cD3_N[i,0],f4_cD3_N[i,0]]=build_features(coeff_cD3.T[:,i])\n",
    "\n",
    "# create features of class I and cD4\n",
    "f1_cD4_N   = np.zeros((100,1))\n",
    "f2_cD4_N   = np.zeros((100,1))\n",
    "f3_cD4_N   = np.zeros((100,1))\n",
    "f4_cD4_N   = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD4_N[i,0],f2_cD4_N[i,0],f3_cD4_N[i,0],f4_cD4_N[i,0]]=build_features(coeff_cD4.T[:,i])\n",
    "    \n",
    "# create features of class I and cD5\n",
    "f1_cD5_N   = np.zeros((100,1))\n",
    "f2_cD5_N   = np.zeros((100,1))\n",
    "f3_cD5_N   = np.zeros((100,1))\n",
    "f4_cD5_N   = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD5_N[i,0],f2_cD5_N[i,0],f3_cD5_N[i,0],f4_cD5_N[i,0]]=build_features(coeff_cD5.T[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f0222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class II (INTERICTAL and cA)\n",
    "f1_cA_I    = np.zeros((100,1))\n",
    "f2_cA_I    = np.zeros((100,1))\n",
    "f3_cA_I    = np.zeros((100,1))\n",
    "f4_cA_I    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cA_I[i,0],f2_cA_I[i,0],f3_cA_I[i,0],f4_cA_I[i,0]]=build_features(coeff_cA_I.T[:,i])\n",
    "\n",
    "# # create features of class II (INTERICTAL and cD1)\n",
    "# f1_cD1_I    = np.zeros((100,1))\n",
    "# f2_cD1_I    = np.zeros((100,1))\n",
    "# f3_cD1_I    = np.zeros((100,1))\n",
    "# f4_cD1_I    = np.zeros((100,1))\n",
    "\n",
    "# for i in range(100):\n",
    "#     [f1_cD1_I[i,0],f2_cD1_I[i,0],f3_cD1_I[i,0],f4_cD1_I[i,0]]=build_features(coeff_cD1_I.T[:,i])\n",
    "\n",
    "# create features of class II (INTERICTAL and cD2)\n",
    "f1_cD2_I    = np.zeros((100,1))\n",
    "f2_cD2_I    = np.zeros((100,1))\n",
    "f3_cD2_I    = np.zeros((100,1))\n",
    "f4_cD2_I    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD2_I[i,0],f2_cD2_I[i,0],f3_cD2_I[i,0],f4_cD2_I[i,0]]=build_features(coeff_cD2_I.T[:,i])\n",
    "    \n",
    "# create features of class II (INTERICTAL and cD3)\n",
    "f1_cD3_I    = np.zeros((100,1))\n",
    "f2_cD3_I    = np.zeros((100,1))\n",
    "f3_cD3_I    = np.zeros((100,1))\n",
    "f4_cD3_I    = np.zeros((100,1))\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD3_I[i,0],f2_cD3_I[i,0],f3_cD3_I[i,0],f4_cD3_I[i,0]]=build_features(coeff_cD3_I.T[:,i])\n",
    "    \n",
    "\n",
    "# create features of class II (INTERICTAL and cD4)\n",
    "f1_cD4_I    = np.zeros((100,1))\n",
    "f2_cD4_I    = np.zeros((100,1))\n",
    "f3_cD4_I    = np.zeros((100,1))\n",
    "f4_cD4_I    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD4_I[i,0],f2_cD4_I[i,0],f3_cD4_I[i,0],f4_cD4_I[i,0]]=build_features(coeff_cD4_I.T[:,i])\n",
    "\n",
    "# create features of class II (INTERICTAL and cD5)\n",
    "f1_cD5_I    = np.zeros((100,1))\n",
    "f2_cD5_I    = np.zeros((100,1))\n",
    "f3_cD5_I    = np.zeros((100,1))\n",
    "f4_cD5_I    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD5_I[i,0],f2_cD5_I[i,0],f3_cD5_I[i,0],f4_cD5_I[i,0]]=build_features(coeff_cD5_I.T[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features of class III (SEIZURE and cA)\n",
    "f1_cA_S    = np.zeros((100,1))\n",
    "f2_cA_S    = np.zeros((100,1))\n",
    "f3_cA_S    = np.zeros((100,1))\n",
    "f4_cA_S    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cA_S[i,0],f2_cA_S[i,0],f3_cA_S[i,0],f4_cA_S[i,0]]=build_features(coeff_cA_S.T[:,i])\n",
    "\n",
    "# # create features of class III (SEIZURE and cD1)\n",
    "# f1_cD1_S    = np.zeros((100,1))\n",
    "# f2_cD1_S    = np.zeros((100,1))\n",
    "# f3_cD1_S    = np.zeros((100,1))\n",
    "# f4_cD1_S    = np.zeros((100,1))\n",
    "\n",
    "# for i in range(100):\n",
    "#     [f1_cD1_S[i,0],f2_cD1_S[i,0],f3_cD1_S[i,0],f4_cD1_S[i,0]]=build_features(coeff_cD1_S.T[:,i])\n",
    "\n",
    "# create features of class III (SEIZURE and cD2)\n",
    "f1_cD2_S    = np.zeros((100,1))\n",
    "f2_cD2_S    = np.zeros((100,1))\n",
    "f3_cD2_S    = np.zeros((100,1))\n",
    "f4_cD2_S    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD2_S[i,0],f2_cD2_S[i,0],f3_cD2_S[i,0],f4_cD2_S[i,0]]=build_features(coeff_cD2_S.T[:,i])\n",
    "    \n",
    "# create features of class III (SEIZURE and cD3)\n",
    "f1_cD3_S    = np.zeros((100,1))\n",
    "f2_cD3_S    = np.zeros((100,1))\n",
    "f3_cD3_S    = np.zeros((100,1))\n",
    "f4_cD3_S    = np.zeros((100,1))\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD3_S[i,0],f2_cD3_S[i,0],f3_cD3_S[i,0],f4_cD3_S[i,0]]=build_features(coeff_cD3_S.T[:,i])\n",
    "    \n",
    "\n",
    "# create features of class III (SEIZURE and cD4)\n",
    "f1_cD4_S    = np.zeros((100,1))\n",
    "f2_cD4_S    = np.zeros((100,1))\n",
    "f3_cD4_S    = np.zeros((100,1))\n",
    "f4_cD4_S    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD4_S[i,0],f2_cD4_S[i,0],f3_cD4_S[i,0],f4_cD4_S[i,0]]=build_features(coeff_cD4_S.T[:,i])\n",
    "\n",
    "# create features of class III (SEIZURE and cD5)\n",
    "f1_cD5_S    = np.zeros((100,1))\n",
    "f2_cD5_S    = np.zeros((100,1))\n",
    "f3_cD5_S    = np.zeros((100,1))\n",
    "f4_cD5_S    = np.zeros((100,1))\n",
    "\n",
    "for i in range(100):\n",
    "    [f1_cD5_S[i,0],f2_cD5_S[i,0],f3_cD5_S[i,0],f4_cD5_S[i,0]]=build_features(coeff_cD5_S.T[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dff0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_N  = np.zeros((100,1))\n",
    "cl_I  = np.ones((100,1))\n",
    "cl_S  = np.full((100,1),[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5226be",
   "metadata": {},
   "outputs": [],
   "source": [
    "MftN = np.concatenate([f1_cA_N, f2_cA_N, f3_cA_N, f4_cA_N,f1_cD2_N,f2_cD2_N,f3_cD2_N,f4_cD2_N,f1_cD3_N,f2_cD3_N,f3_cD3_N,f4_cD3_N,f1_cD4_N,f2_cD4_N,f3_cD4_N,f4_cD4_N,f1_cD5_N,f2_cD5_N,f3_cD5_N,f4_cD5_N,cl_N], axis=1)\n",
    "\n",
    "MftI = np.concatenate([f1_cA_I, f2_cA_I, f3_cA_I, f4_cA_I,f1_cD2_I,f2_cD2_I,f3_cD2_I,f4_cD2_I,f1_cD3_I,f2_cD3_I,f3_cD3_I,f4_cD3_I,f1_cD4_I,f2_cD4_I,f3_cD4_I,f4_cD4_I,f1_cD5_I,f2_cD5_I,f3_cD5_I,f4_cD5_I,cl_I], axis=1)\n",
    "\n",
    "MftS = np.concatenate([f1_cA_S, f2_cA_S, f3_cA_S, f4_cA_S,f1_cD2_S,f2_cD2_S,f3_cD2_S,f4_cD2_S,f1_cD3_S,f2_cD3_S,f3_cD3_S,f4_cD3_S,f1_cD4_S,f2_cD4_S,f3_cD4_S,f4_cD4_S,f1_cD5_S,f2_cD5_S,f3_cD5_S,f4_cD5_S,cl_S], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d38d1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "FCM_N  = pd.DataFrame(MftN,columns=['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','class'])\n",
    "\n",
    "FCM_I  = pd.DataFrame(MftI,columns=['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','class'])\n",
    "\n",
    "FCM_S  = pd.DataFrame(MftS,columns=['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20','class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697cedbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalDataset = pd.concat([FCM_N,FCM_I,FCM_S],ignore_index=True)\n",
    "print(TotalDataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f74fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0fb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TotalDataset[['f1','f2','f3','f4','f5','f6','f7','f8','f9','f10','f11','f12','f13','f14','f15','f16','f17','f18','f19','f20']]\n",
    "y = TotalDataset[['class']]\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dece1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6413f07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7361103",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92290302",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4da3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36874f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=X_train.reshape(X_train.shape[0],20,1)\n",
    "y_train=y_train.reshape(y_train.shape[0],1)\n",
    "x_test=X_test.reshape(X_test.shape[0],20,1)\n",
    "y_test=y_test.reshape(y_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9577ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ab641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Conv1D \n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(20, 1)))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "history=model.fit(x_train, y_train, batch_size = 64, epochs = 100)\n",
    "score=model.evaluate(x_test,y_test,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4369234",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('AvsCvsE accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['Accuracy'],loc='best')\n",
    "plt.savefig('20-AvsCvsE_Accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c7ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('AvsCvsE Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['Loss'],loc='best')\n",
    "plt.savefig('20-AvsCvsE_Loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea29ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817de164",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05711a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=np.argmax(y_pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47032c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60969318",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual=y_test\n",
    "predicted=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e531c2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = metrics.confusion_matrix(actual, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edcdc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e502fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions( y_test, y_pred)\n",
    "plt.savefig('20-AvsCvsE_ConfusionMatrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807d628d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
